{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready loading data\n",
      "Python version: 3.9.19 (main, May  6 2024, 20:12:36) [MSC v.1916 64 bit (AMD64)]\n",
      "Conda environment: base\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datasets import load_dataset \n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig \n",
    "from transformers import pipeline\n",
    "print('ready loading data')\n",
    "\n",
    "# Check Python version\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "# Check Conda environment\n",
    "conda_env = os.environ.get('CONDA_DEFAULT_ENV')\n",
    "print(\"Conda environment:\", conda_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bciez\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Once upon a time, when we were under great pressure. We got to a place that was more than ten thousand square metres. In the course of a short period of time, it became the most-loved city in our land. We saw'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "# generation pipeline\n",
    "generator = pipeline('text-generation',model='gpt2')\n",
    "\n",
    "# example of text generation\n",
    "result=generator(\"Once upon a time,\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\bciez\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York city is famous for its urban centers and can be hard to find in the surrounding areas. Luckily with the introduction of the New York's Metropolitan Transit Authority, its location and popularity are increasing exponentially. There are now more \"Bikers\" and \"Migrant\" sections in every city.\n",
      "\n",
      "These are actually very much in a city of 9 million unique people. The main difference between the cities in California and Florida or Colorado and their regional neighbors is that Florida and Florida are the most progressive areas in their respective states. They all have their own city hall, parks, public transportation and they have their own budgeting system. It doesn't really matter in terms of what the city gets their money for, they can make up their own budget\n"
     ]
    }
   ],
   "source": [
    "llm =  pipeline('text-generation')\n",
    "prompt = \"New York city is famous for\"\n",
    "outputs = llm(prompt, max_length=150)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
